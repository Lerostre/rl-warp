{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ivanov.dko/projects/test/rl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM\n",
    ")\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from warp.utils.data import prepare_warp_dataset\n",
    "from warp.constants import DATASET_DIR, CONFIG_DIR, MODEL_DIR\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%cd ..\n",
    "%autoreload 2\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этот раз нам нужны две модели. Одну из них мы предположительно обучили в прошлом ноутбуке. Если по какой-то причине она не лежит в `artifacts/reward_model`, можно скачать какую-то другую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = Path(MODEL_DIR, \"reward_model\")\n",
    "# model_name = \"lvwerra/distilbert-imdb\"\n",
    "\n",
    "reward_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name, max_length=512, use_fast=True\n",
    ")\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось только оценить, насколько модель хороша. Одна у нас уже должна быть с прошлого ноутбука, если нет, то запустим ячейку ниже. В остальном нужно поварьировать параметр и оценить, насколько он вообще на что-то влияет. Я предлагаю взглянуть на $\\eta$, потому что у него есть прикольная зависимость от KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default\n",
    "!poetry run python warp/train_warp.py --config-name warp_config run_name=warp_model trainer.eta=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eta=0.1\n",
    "!poetry run python warp/train_warp.py --config-name warp_config run_name=warp_low_eta trainer.eta=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eta=0.9\n",
    "!poetry run python warp/train_warp.py --config-name warp_config run_name=warp_high_eta trainer.eta=0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь измерим средний реворд и дивергенцию предложений. KL между SFT и SFT не имеет смысла, предлагаю это опустить. Ну и в какой-то момент я психанул, потому что сохранялись только веса адаптера, так что веса у меня в пикле. Это некрасиво, конечно. К тому же возник баг, из-за которого не получалось десериализовать модель обратно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else: return super().find_class(module, name)\n",
    "\n",
    "def get_model(name):\n",
    "    model_name = Path(MODEL_DIR, name)\n",
    "    try:\n",
    "        sft_model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name\n",
    "    )\n",
    "    except:\n",
    "        with open(model_name, \"rb\") as f:\n",
    "            sft_model = CPU_Unpickler(f).load()\n",
    "    return sft_model\n",
    "\n",
    "\n",
    "tokenizer_name = Path(MODEL_DIR, \"lvwerra/gpt2-imdb\")\n",
    "sft_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    tokenizer_name, max_length=512, use_fast=True\n",
    ")\n",
    "sft_tokenizer.pad_token = sft_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы оценивать результаты, надо бы вообще завести отдельную функцию, стоило сделать сразу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(prompt, response):\n",
    "    return (\n",
    "        torch.stack(\n",
    "            [\n",
    "                reward_model(\n",
    "                    **reward_tokenizer(\n",
    "                        input,\n",
    "                        padding=True,\n",
    "                        return_tensors=\"pt\",\n",
    "                    )\n",
    "                ).logits.detach()\n",
    "                for input in [prompt, response]\n",
    "            ]\n",
    "        )\n",
    "        .mean(dim=2)\n",
    "        .softmax(0)[1, :]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warp.utils.train import policy\n",
    "\n",
    "\n",
    "def generate_from_prompt(model, prompt=None, input_ids=None):\n",
    "    if input_ids is None:\n",
    "        input_ids = sft_tokenizer([prompt], return_tensors=\"pt\")[\"input_ids\"]\n",
    "    else:\n",
    "        prompt = sft_tokenizer.batch_decode(input_ids)[0]\n",
    "    completion_ids = model.generate(\n",
    "        temperature=0.9,\n",
    "        do_sample=True,\n",
    "        pad_token_id=sft_tokenizer.eos_token_id,\n",
    "        input_ids=input_ids,\n",
    "    )\n",
    "    completion = sft_tokenizer.batch_decode(completion_ids)\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"completion\": completion[0],\n",
    "        \"logps\": policy(model, completion_ids, len_generated=10)[0],\n",
    "        \"reward\": get_reward(prompt, completion[0])[0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет у нас фактически тот же, так что можно украсть код у себя самого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-06 02:14:55.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mwarp.utils.data\u001b[0m:\u001b[36mprepare_warp_dataset\u001b[0m:\u001b[36m164\u001b[0m - \u001b[1mStarting tokenizing `text`\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "test = load_dataset(\"imdb\", split=\"test\").to_pandas()\n",
    "test = prepare_warp_dataset(\n",
    "    pl.DataFrame(test).sample(100).to_dict(as_series=False),\n",
    "    tokenizer=sft_tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'text'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь осталось прогнать на нём каждую модель и посчитать KL + Reward. Reward буду точно так же считать, сравнивая prompt и completion\n",
    "\n",
    "Веса использованных моделей лежат [тут](https://drive.google.com/file/d/1H5ppIlJP4M2Fy3Dl1F85ERheSaJD1tFH/view?usp=sharing), [тут](https://drive.google.com/file/d/1-7A5sObWbIGyZjSxQYv-ZD_E1lzH7OjK/view?usp=drive_link) и [тут](https://drive.google.com/file/d/1-5MLpNCg2_xb3H_y5v8PGk_ESv-0qE4D/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(\"warp_low_eta.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warp.utils.misc import seed_everything\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "answers = []\n",
    "for _ in range(5): # чтоб выборка была побольше\n",
    "    for key in [\n",
    "        \"lvwerra/gpt2-imdb\",\n",
    "        \"warp_model.pkl\",\n",
    "        \"warp_low_eta.pkl\",\n",
    "        \"warp_high_eta.pkl\",\n",
    "    ]:\n",
    "        model = get_model(key)\n",
    "        sub_df = test.map(\n",
    "            lambda x: generate_from_prompt(\n",
    "                model, input_ids=x[\"input_ids\"].unsqueeze(0)\n",
    "            )\n",
    "        ).to_pandas()\n",
    "        sub_df[\"model\"] = key\n",
    "        answers.append(pl.DataFrame(sub_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь осталось это нормально изобразить. Как обычно, придётся немного повозиться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model</th><th>logps</th><th>reward</th><th>kl_div</th><th>eta</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;lvwerra/gpt2-imdb&quot;</td><td>-30.611758</td><td>0.487238</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;warp_high_eta.pkl&quot;</td><td>-30.888689</td><td>0.503654</td><td>-0.276932</td><td>0.9</td></tr><tr><td>&quot;warp_low_eta.pkl&quot;</td><td>-30.540535</td><td>0.494633</td><td>0.071223</td><td>0.1</td></tr><tr><td>&quot;warp_model.pkl&quot;</td><td>-30.468174</td><td>0.509606</td><td>0.143584</td><td>0.5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 5)\n",
       "┌───────────────────┬────────────┬──────────┬───────────┬─────┐\n",
       "│ model             ┆ logps      ┆ reward   ┆ kl_div    ┆ eta │\n",
       "│ ---               ┆ ---        ┆ ---      ┆ ---       ┆ --- │\n",
       "│ str               ┆ f64        ┆ f64      ┆ f64       ┆ f64 │\n",
       "╞═══════════════════╪════════════╪══════════╪═══════════╪═════╡\n",
       "│ lvwerra/gpt2-imdb ┆ -30.611758 ┆ 0.487238 ┆ 0.0       ┆ 0.0 │\n",
       "│ warp_high_eta.pkl ┆ -30.888689 ┆ 0.503654 ┆ -0.276932 ┆ 0.9 │\n",
       "│ warp_low_eta.pkl  ┆ -30.540535 ┆ 0.494633 ┆ 0.071223  ┆ 0.1 │\n",
       "│ warp_model.pkl    ┆ -30.468174 ┆ 0.509606 ┆ 0.143584  ┆ 0.5 │\n",
       "└───────────────────┴────────────┴──────────┴───────────┴─────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated = (\n",
    "    pl.concat(answers).group_by(\"model\").agg(pl.col(\"logps\", \"reward\").mean())\n",
    ").sort(\"model\")\n",
    "sft_kl_div = aggregated.filter(pl.col(\"model\") == \"lvwerra/gpt2-imdb\")[\"logps\"][0]\n",
    "all_stats = aggregated.with_columns(\n",
    "    kl_div=pl.col(\"logps\") - sft_kl_div, eta=pl.Series([0.0, 0.9, 0.1, 0.5])\n",
    ")\n",
    "all_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У пытливого читателя может возникнуть вопрос - как KL может быть меньше 0. Ответ - я не знаю, возможно здесь и кроется моя ошибка. Но меня и в самой статье смутило, что KL не в совсем привычном мне виде. Там нет суммы, там нет вероятности, это всё очень странно, но по тому, что я гуглил, ошибки там нет. Но может быть есть у меня. Я предлагаю немножко на это забить, потому что вопрос \"а между чем вообще считать KL\" в любом случае останется без ответа, но да, я вижу проблему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p2107'>\n",
       "  <div id=\"ac54ccb1-b1ac-40c5-9ee0-c18589c5c1d5\" data-root-id=\"p2107\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"f4459aad-09d2-4060-ae6d-79c051247078\":{\"version\":\"3.5.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Row\",\"id\":\"p2107\",\"attributes\":{\"name\":\"Row02750\",\"tags\":[\"embedded\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"p2110\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.5.0-b.2/dist/css/loading.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"p2173\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.5.0-b.2/dist/css/listpanel.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"p2108\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.5.0-b.2/dist/bundled/theme/default.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"p2109\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.5.0-b.2/dist/bundled/theme/native.css\"}}],\"min_width\":700,\"margin\":0,\"sizing_mode\":\"stretch_width\",\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"Spacer\",\"id\":\"p2111\",\"attributes\":{\"name\":\"HSpacer02757\",\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"p2110\"},{\"id\":\"p2108\"},{\"id\":\"p2109\"}],\"margin\":0,\"sizing_mode\":\"stretch_width\",\"align\":\"start\"}},{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p2119\",\"attributes\":{\"width\":700,\"height\":300,\"margin\":[5,10],\"sizing_mode\":\"fixed\",\"align\":\"start\",\"x_range\":{\"type\":\"object\",\"name\":\"Range1d\",\"id\":\"p2112\",\"attributes\":{\"tags\":[[[\"kl_div\",null]],[]],\"start\":-0.29495373883928705,\"end\":0.16160608258928458,\"reset_start\":-0.29495373883928705,\"reset_end\":0.16160608258928458}},\"y_range\":{\"type\":\"object\",\"name\":\"Range1d\",\"id\":\"p2113\",\"attributes\":{\"tags\":[[[\"reward\",null]],{\"type\":\"map\",\"entries\":[[\"invert_yaxis\",false],[\"autorange\",false]]}],\"start\":0.48500080261230466,\"end\":0.5118428558349609,\"reset_start\":0.48500080261230466,\"reset_end\":0.5118428558349609}},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p2129\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p2130\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p2122\",\"attributes\":{\"text\":\"KL-Eta relation\",\"text_color\":\"black\",\"text_font_size\":\"12pt\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p2164\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p2153\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p2154\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p2155\"},\"data\":{\"type\":\"map\",\"entries\":[[\"kl_div\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAAAAAACAke18P7nRvwD3U+OlO7I/AFyPwvVgwj8=\"},\"shape\":[4],\"dtype\":\"float64\",\"order\":\"little\"}],[\"reward\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"WDm0yOYu3z8OLbKd7x3gP42XbhITqN8/exSuR7FO4D8=\"},\"shape\":[4],\"dtype\":\"float64\",\"order\":\"little\"}],[\"eta\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAAAAAADNzMzMzMzsP5qZmZmZmbk/AAAAAAAA4D8=\"},\"shape\":[4],\"dtype\":\"float64\",\"order\":\"little\"}],[\"color\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAAAAAADNzMzMzMzsP5qZmZmZmbk/AAAAAAAA4D8=\"},\"shape\":[4],\"dtype\":\"float64\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p2165\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p2166\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p2159\",\"attributes\":{\"tags\":[\"apply_ranges\"],\"x\":{\"type\":\"field\",\"field\":\"kl_div\"},\"y\":{\"type\":\"field\",\"field\":\"reward\"},\"size\":{\"type\":\"value\",\"value\":5.477225575051661},\"line_color\":{\"type\":\"field\",\"field\":\"color\",\"transform\":{\"type\":\"object\",\"name\":\"LinearColorMapper\",\"id\":\"p2152\",\"attributes\":{\"palette\":[\"#b3fef5\",\"#b0fef5\",\"#adfdf5\",\"#a9fcf5\",\"#a6fbf6\",\"#a3faf6\",\"#a0faf6\",\"#9df9f6\",\"#9af8f6\",\"#97f7f6\",\"#93f7f6\",\"#90f6f6\",\"#8df5f6\",\"#8af4f7\",\"#87f3f7\",\"#83f2f7\",\"#80f2f7\",\"#7df1f7\",\"#79f0f7\",\"#76eff7\",\"#73eef7\",\"#6fedf8\",\"#6cecf8\",\"#68ecf8\",\"#65ebf8\",\"#61eaf8\",\"#5ee9f8\",\"#5ae8f8\",\"#57e7f8\",\"#53e6f8\",\"#50e5f9\",\"#4ce4f9\",\"#49e3f9\",\"#45e2f9\",\"#42e1f9\",\"#3ee0f9\",\"#3bdff9\",\"#38def9\",\"#35ddf9\",\"#32dcf9\",\"#30dbfa\",\"#2ed9fa\",\"#2dd8fa\",\"#2cd7fa\",\"#2bd6fa\",\"#2bd5fa\",\"#2ad3fa\",\"#2ad2fa\",\"#29d1fa\",\"#29d0fb\",\"#29cffb\",\"#28cdfb\",\"#28ccfb\",\"#28cbfb\",\"#28cafb\",\"#28c8fb\",\"#28c7fb\",\"#29c6fb\",\"#29c5fb\",\"#29c4fb\",\"#29c2fb\",\"#2ac1fb\",\"#2ac0fb\",\"#2bbffb\",\"#2bbdfc\",\"#2cbcfc\",\"#2dbbfc\",\"#2db9fc\",\"#2eb8fc\",\"#2fb7fc\",\"#2fb6fc\",\"#30b4fc\",\"#31b3fc\",\"#32b2fc\",\"#32b0fc\",\"#33affc\",\"#33aefc\",\"#34adfc\",\"#34abfc\",\"#34aafc\",\"#35a9fc\",\"#35a8fc\",\"#35a6fc\",\"#35a5fc\",\"#35a4fc\",\"#35a3fc\",\"#35a1fc\",\"#35a0fc\",\"#359ffc\",\"#359dfc\",\"#359cfc\",\"#359bfc\",\"#349afd\",\"#3498fd\",\"#3497fd\",\"#3396fd\",\"#3395fd\",\"#3293fd\",\"#3292fd\",\"#3191fd\",\"#3090fd\",\"#308ffd\",\"#2f8dfd\",\"#2f8cfd\",\"#2e8bfd\",\"#2e8afd\",\"#2d88fd\",\"#2d87fd\",\"#2c86fd\",\"#2c84fd\",\"#2c83fd\",\"#2c82fd\",\"#2b81fd\",\"#2b7ffd\",\"#2b7efd\",\"#2b7dfd\",\"#2b7bfd\",\"#2b7afd\",\"#2b79fd\",\"#2b77fd\",\"#2b76fd\",\"#2b75fd\",\"#2b73fd\",\"#2c72fd\",\"#2c71fd\",\"#2c6ffd\",\"#2c6efd\",\"#2d6cfd\",\"#2d6bfd\",\"#2d6afc\",\"#2e68fc\",\"#2e67fc\",\"#2e65fc\",\"#2e64fc\",\"#2f62fc\",\"#2f61fc\",\"#2f5ffc\",\"#2f5efc\",\"#2f5dfc\",\"#2f5bfc\",\"#2f5afc\",\"#2f58fb\",\"#2f57fb\",\"#2f55fb\",\"#2f53fb\",\"#2f52fb\",\"#2f50fb\",\"#2f4ffb\",\"#2f4dfb\",\"#2e4cfb\",\"#2e4afb\",\"#2e48fb\",\"#2e47fa\",\"#2d45fa\",\"#2d43fa\",\"#2d42fa\",\"#2d40fa\",\"#2c3efa\",\"#2c3dfa\",\"#2b3bf9\",\"#2b39f9\",\"#2a37f9\",\"#2a36f8\",\"#2934f8\",\"#2832f7\",\"#2831f7\",\"#272ff6\",\"#262ef5\",\"#252cf5\",\"#252af4\",\"#2429f3\",\"#2327f2\",\"#2226f1\",\"#2124f0\",\"#2023ef\",\"#1f22ee\",\"#1e20ed\",\"#1d1feb\",\"#1c1eea\",\"#1b1ce9\",\"#1a1be7\",\"#181ae6\",\"#1719e5\",\"#1618e3\",\"#1417e1\",\"#1316e0\",\"#1215de\",\"#1014dc\",\"#0f13db\",\"#0e12d9\",\"#0d11d7\",\"#0c10d5\",\"#0b0fd3\",\"#0a0ed1\",\"#090dd0\",\"#080dce\",\"#080ccc\",\"#070bca\",\"#070ac8\",\"#0709c6\",\"#0708c4\",\"#0707c2\",\"#0707bf\",\"#0806bd\",\"#0806bb\",\"#0905b9\",\"#0904b7\",\"#0a04b5\",\"#0a04b2\",\"#0b03b0\",\"#0c03ae\",\"#0d02ab\",\"#0e02a9\",\"#0e02a7\",\"#0f02a4\",\"#0f01a2\",\"#1001a0\",\"#10019d\",\"#10019b\",\"#100199\",\"#100197\",\"#100194\",\"#0f0192\",\"#0f0190\",\"#0f018e\",\"#0e018b\",\"#0e0189\",\"#0d0187\",\"#0d0185\",\"#0c0183\",\"#0b0181\",\"#0b017e\",\"#0a017c\",\"#09017a\",\"#090178\",\"#080276\",\"#070274\",\"#060272\",\"#060270\",\"#05026e\",\"#04026c\",\"#030269\",\"#030267\",\"#020265\",\"#010263\",\"#010261\",\"#00025f\",\"#00025d\",\"#00025b\",\"#000259\",\"#000257\",\"#000255\",\"#000154\",\"#000152\",\"#000150\",\"#00004e\"],\"low\":0.0,\"high\":0.9}}},\"fill_color\":{\"type\":\"field\",\"field\":\"color\",\"transform\":{\"id\":\"p2152\"}},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\",\"transform\":{\"id\":\"p2152\"}}}},\"selection_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p2161\",\"attributes\":{\"tags\":[\"apply_ranges\"],\"x\":{\"type\":\"field\",\"field\":\"kl_div\"},\"y\":{\"type\":\"field\",\"field\":\"reward\"},\"size\":{\"type\":\"value\",\"value\":5.477225575051661},\"line_color\":{\"type\":\"field\",\"field\":\"color\",\"transform\":{\"id\":\"p2152\"}},\"fill_color\":{\"type\":\"field\",\"field\":\"color\",\"transform\":{\"id\":\"p2152\"}},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\",\"transform\":{\"id\":\"p2152\"}}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p2160\",\"attributes\":{\"tags\":[\"apply_ranges\"],\"x\":{\"type\":\"field\",\"field\":\"kl_div\"},\"y\":{\"type\":\"field\",\"field\":\"reward\"},\"size\":{\"type\":\"value\",\"value\":5.477225575051661},\"line_color\":{\"type\":\"field\",\"field\":\"color\",\"transform\":{\"id\":\"p2152\"}},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"field\",\"field\":\"color\",\"transform\":{\"id\":\"p2152\"}},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\",\"transform\":{\"id\":\"p2152\"}},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"hover_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p2162\",\"attributes\":{\"tags\":[\"apply_ranges\"],\"x\":{\"type\":\"field\",\"field\":\"kl_div\"},\"y\":{\"type\":\"field\",\"field\":\"reward\"},\"size\":{\"type\":\"value\",\"value\":5.477225575051661},\"line_color\":{\"type\":\"field\",\"field\":\"color\",\"transform\":{\"id\":\"p2152\"}},\"fill_color\":{\"type\":\"field\",\"field\":\"color\",\"transform\":{\"id\":\"p2152\"}},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\",\"transform\":{\"id\":\"p2152\"}}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p2163\",\"attributes\":{\"tags\":[\"apply_ranges\"],\"x\":{\"type\":\"field\",\"field\":\"kl_div\"},\"y\":{\"type\":\"field\",\"field\":\"reward\"},\"size\":{\"type\":\"value\",\"value\":5.477225575051661},\"line_color\":{\"type\":\"field\",\"field\":\"color\",\"transform\":{\"id\":\"p2152\"}},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"field\",\"field\":\"color\",\"transform\":{\"id\":\"p2152\"}},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_color\":{\"type\":\"field\",\"field\":\"color\",\"transform\":{\"id\":\"p2152\"}},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p2128\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p2117\",\"attributes\":{\"tags\":[\"hv_created\"],\"renderers\":\"auto\",\"zoom_together\":\"none\"}},{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"p2118\",\"attributes\":{\"tags\":[\"hv_created\"],\"renderers\":[{\"id\":\"p2164\"}],\"tooltips\":[[\"kl_div\",\"@{kl_div}\"],[\"reward\",\"@{reward}\"],[\"eta\",\"@{eta}\"]]}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p2141\"},{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p2142\"},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p2143\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p2144\",\"attributes\":{\"syncable\":false,\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5,\"level\":\"overlay\",\"visible\":false,\"left\":{\"type\":\"number\",\"value\":\"nan\"},\"right\":{\"type\":\"number\",\"value\":\"nan\"},\"top\":{\"type\":\"number\",\"value\":\"nan\"},\"bottom\":{\"type\":\"number\",\"value\":\"nan\"},\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"top_units\":\"canvas\",\"bottom_units\":\"canvas\",\"handles\":{\"type\":\"object\",\"name\":\"BoxInteractionHandles\",\"id\":\"p2150\",\"attributes\":{\"all\":{\"type\":\"object\",\"name\":\"AreaVisuals\",\"id\":\"p2149\",\"attributes\":{\"fill_color\":\"white\",\"hover_fill_color\":\"lightgray\"}}}}}}}},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p2151\"}],\"active_drag\":{\"id\":\"p2142\"},\"active_scroll\":{\"id\":\"p2117\"}}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p2136\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p2137\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p2138\"},\"axis_label\":\"reward\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p2139\"}}}],\"right\":[{\"type\":\"object\",\"name\":\"ColorBar\",\"id\":\"p2168\",\"attributes\":{\"location\":[0,0],\"title\":\"eta\",\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p2167\",\"attributes\":{\"mantissas\":[1,2,5]}},\"major_label_policy\":{\"type\":\"object\",\"name\":\"NoOverlap\",\"id\":\"p2169\"},\"label_standoff\":8,\"major_tick_line_color\":\"black\",\"bar_line_color\":\"black\",\"color_mapper\":{\"id\":\"p2152\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p2131\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p2132\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p2133\"},\"axis_label\":\"kl_div\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p2134\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p2135\",\"attributes\":{\"axis\":{\"id\":\"p2131\"},\"ticker\":{\"id\":\"p2132\"}}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p2140\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p2136\"},\"ticker\":{\"id\":\"p2137\"}}}],\"min_border_top\":10,\"min_border_bottom\":10,\"min_border_left\":10,\"min_border_right\":10,\"output_backend\":\"webgl\"}},{\"type\":\"object\",\"name\":\"Spacer\",\"id\":\"p2171\",\"attributes\":{\"name\":\"HSpacer02758\",\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"p2110\"},{\"id\":\"p2108\"},{\"id\":\"p2109\"}],\"margin\":0,\"sizing_mode\":\"stretch_width\",\"align\":\"start\"}}]}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"f4459aad-09d2-4060-ae6d-79c051247078\",\"roots\":{\"p2107\":\"ac54ccb1-b1ac-40c5-9ee0-c18589c5c1d5\"},\"root_ids\":[\"p2107\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       ":Scatter   [kl_div]   (reward,eta)"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p2107"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stats.plot.scatter(\n",
    "    \"kl_div\",\n",
    "    \"reward\",\n",
    "    color=\"eta\",\n",
    "    title=\"KL-Eta relation\",\n",
    "    grid=True,\n",
    "    colorbar=True,\n",
    "    clabel=\"eta\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По итогу всё равно к сожалению получилось что-то не то. Должно было быть вот как:\n",
    "1. $\\eta = 0$ означает, что модель фактически не обновляется никак и сохраняет то же распределение, что и было, то есть KL практически нулевой, но и награды мы никакой не получаем, потому что не обучаемся толком. У меня награда действительно маленькая, ниже всех, тут успех. С дивергенцией - скорее всего косяк, хотя по модулю она действительно тоже меньше всех\n",
    "2. Наоборот означает, что мы обучаемся со всей дури, и распределение меняется тоже очень сильно. Если KL по модулю действительно больше всех, тут ещё ладно, то reward, к сожалению, не наибольший. Возможно я не совсем верно его замеряю, либо же не совсем честно его проверяю. Мне кажется, что тестовых примеров маловато, плюс генерации сами по себе подвержены рандому, тут нужно немножко похитрее это сделать, в идеале с какими-то CI\n",
    "\n",
    "А остальные параметры уже толком и не проверю. Я довольно много игрался с $I$ - числом итераций, но там разумно предположить, что чем их меньше, тем хуже модель обучается - меньше KL, меньше reward. И должно это быть верно для любого гиперпараметры с итерациями - по картинке парето фронт просто съезжает вверх\n",
    "\n",
    "Так что итог: что-то конечно получилось, но что?\n",
    "Напоследок хотя бы примеры генераций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['What has Rajiv Rai done to himself? Once a hit director of films',\n",
       "        'What has Rajiv Rai done to himself? Once a hit director of films like this has done it'],\n",
       "       [\"I'm not from USA I'm from central Europe and i think the show\",\n",
       "        \"I'm not from USA I'm from central Europe and i think the show is stupid. The characters\"],\n",
       "       ['A female ex-cop who was drummed out of the force for reck',\n",
       "        'A female ex-cop who was drummed out of the force for recklessly killing a cop is'],\n",
       "       ['Oh, man, I hated this movie. Granted, the site locations were',\n",
       "        'Oh, man, I hated this movie. Granted, the site locations were the only \"place to'],\n",
       "       ['Set in Paris in the year 1910, a retired old rich opera singer decides',\n",
       "        'Set in Paris in the year 1910, a retired old rich opera singer decides to escape his old life']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.concat(answers).filter(pl.col(\"model\") == \"warp_high_eta.pkl\").select(\n",
    "    \"prompt\", \"completion\"\n",
    ").sample(5).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Негатив там конечно есть, но наверное не так много"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
