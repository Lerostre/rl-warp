{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM\n",
    ")\n",
    "\n",
    "import os\n",
    "\n",
    "from warp.utils.misc import seed_everything\n",
    "from warp.utils.data import prepare_warp_dataset\n",
    "from warp.constants import DATASET_DIR, CONFIG_DIR, MODEL_DIR\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этот раз нам нужны две модели. Одну из них мы предположительно обучили в прошлом ноутбуке. Если по какой-то причине она не лежит в `artifacts/reward_model`, можно скачать какую-то другую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = Path(MODEL_DIR, \"reward_model\")\n",
    "# model_name = \"lvwerra/distilbert-imdb\"\n",
    "\n",
    "reward_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name, max_length=512, use_fast=True\n",
    ")\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, как она работает. Помним, что наша главная цель - доставать reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.8782, -4.9536],\n",
       "        [ 4.7472,  4.5910],\n",
       "        [ 0.9542,  0.8615]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_model(\n",
    "    **reward_tokenizer(\n",
    "        [\n",
    "            \"this movie is brilliant\",\n",
    "            \"this movie is so bad\",\n",
    "            \"this movie was so so\",\n",
    "        ],\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True\n",
    "    )\n",
    ").logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как я и писал (надеюсь) ранее, сами по себе логиты нам вообще никак не помогут, даже если дать сверху софтмакс. Reward нужно считать друг относительно друга, для этого нужна отдельная функция, по аналогии с той, что есть в `RewardTrainer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(prompt, response):\n",
    "    return (\n",
    "        torch.stack(\n",
    "            [\n",
    "                reward_model(\n",
    "                    **reward_tokenizer(\n",
    "                        input,\n",
    "                        padding=True,\n",
    "                        return_tensors=\"pt\",\n",
    "                    )\n",
    "                ).logits.detach()\n",
    "                for input in [prompt, response]\n",
    "            ]\n",
    "        )\n",
    "        .mean(dim=2)\n",
    "        .softmax(0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9821],\n",
       "        [0.0179]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reward(\n",
    "    [\"this movie is\"],\n",
    "    [\"this movie is so damn cool, bro. i've never seen anything better in my life\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, всё отлично - положительные отзывы мы не хотим. Вопрос только в том, что $r$ в статье отрицательный, а $r_{\\beta}$ как будто бы может принимать любые значения, так что софтмакс здесь тоже находится под вопросом. Итого, есть 4 варианта, как понять статью, я пробовал все\n",
    "\n",
    "В любом случае нам нужна SFT-модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = Path(MODEL_DIR, \"lvwerra/gpt2-imdb\")\n",
    "\n",
    "sft_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name, max_length=512, use_fast=True\n",
    ")\n",
    "sft_tokenizer.pad_token = sft_tokenizer.eos_token\n",
    "sft_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, return_dict_in_generate=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В статье указывается только про температуру, её мы пропишем. Уточняется, что они дообучали 28 слоёв, но в самой модели их чуть больше. Хотя они вроде не уточняют, что они брали"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "for param in sft_model.parameters():\n",
    "    if param.requires_grad:\n",
    "        i += 1\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2LMHeadModel(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(50257, 768)\n",
       "        (wpe): Embedding(1024, 768)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-11): 12 x GPT2Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2SdpaAttention(\n",
       "              (c_attn): lora.Linear(\n",
       "                (base_layer): Conv1D()\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2304, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import get_peft_model, TaskType, LoraConfig\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False, \n",
    "    r=16, \n",
    "    lora_alpha=32, \n",
    "    lora_dropout=0.05,\n",
    "    fan_in_fan_out=True\n",
    ")\n",
    "get_peft_model(sft_model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "for param in sft_model.parameters():\n",
    "    if param.requires_grad:\n",
    "        i += 1\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гораздо лучше, это и попробуем тюнить. Сразу скажу, что без адаптера я тоже пробовал, но модель довольно сильно плывём. Хочется думать, что основные её веса норм\n",
    "\n",
    "Следующий шаг - научиться находить полиси $\\pi(y|x)$. Насколько я понимаю, достаточно найти вероятность встретить каждый токен при наличии контекста, а затем перемножить. Это вообще можно достать из генерации, но прикол в том, что полиси нужно оценивать у двух разных моделей, для этого нужно похитрить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_policy(model, input_ids, len_generated):\n",
    "\n",
    "    logits = model(input_ids).logits\n",
    "    shift_logits = logits[..., :-1, :].contiguous()\n",
    "    shift_labels = input_ids[..., 1:].contiguous()\n",
    "    policy = -F.cross_entropy(\n",
    "        shift_logits.transpose(1, 2), shift_labels, reduction=\"none\"\n",
    "    )[:, -len_generated:].sum(-1)\n",
    "\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас в сетапе есть $\\theta$ и $\\theta_{\\text{ema}}$. У них один и тот же токенизатор, что гарантирует, что инпуты они обработают одинаково, это хорошо. Логиты можно достать, если прогнать форвард. Тогда останется посчитать кросс-энтропию от того, что мы нагенерили, получить то, что есть, то есть буквально $(x_n|x_1, ..., x_{n-1})$. Чтобы получить вероятность именно всего предложения, просуммируем логвероятности, как в обычной языковой модели. `len_generated` нужен, чтобы считать вероятность именно генерации. Вообще это костыль и его надо сделать красивее, потому что есть паддинг. Но в нашем сетапе длина везде 10, так что я забил"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = sft_tokenizer([\"this movie is so\"], return_tensors=\"pt\")\n",
    "response_input_ids = sft_model.generate(input_ids, output_scores=True)\n",
    "get_policy(response_input_ids, input_ids, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующий шаг - научится делать интерполяцию. Начнём вот с чего:\n",
    "\n",
    "1. Методы интерполяции в статье делаются для векторов. Веса в сетках, к соэалению, обычно матрицы. Как этого избежать? Я не знаю, но я считал, что каждая матрица это кортеж векторов, каждый из которых я интерполирую\n",
    "2. SLERP делается для двух сущностей, а нам надо интерполировать много. В аппендиксе, если я правильно понял, они итеративно применяют его к каждой паре. Только применять его можно по-разному, например:\n",
    "$$\n",
    "\\theta_{\\text{init}} = \\theta_{\\text{init}} + \\lambda_1\\theta_{1} + \\lambda_2\\theta_{2} \\\\\n",
    "\\theta_{\\text{init}} = \\theta_{\\text{init}} + \\lambda_1(\\theta_{\\text{init}} + \\lambda_2\\theta_{2}) + ...\\theta_{3}\n",
    "$$\n",
    "То есть `slerp(slerp(theta, 1, 2), 3)`. Я же выбрал другой вариант, который, как по мне разумнее. Будем идти окном и мёрджить веса попарно. Изначальный вес добавим в самом конце\n",
    "$$\n",
    "\\theta_{2} = \\lambda_1\\theta_{1} + \\lambda_2\\theta_{2} \\\\\n",
    "... \\\\\n",
    "\\theta_{m} = \\lambda_1\\theta_{m-1} + \\lambda_2\\theta_{m} \\\\\n",
    "\\theta_{\\text{init}} = \\theta_{\\text{init}} + \\theta_{m}\n",
    "$$\n",
    "В общем, тут можно поразмышлять, как сделать лучше. Мне кажется, что это ни на что особо не повлияет, проверить к сожалению не успею, но вот идейка, как можно модернизировать\n",
    "\n",
    "3. Ручные обновления параметров надо сделать чуть покрасивее, чем это сделал сейчас я, тут каюсь, есть куда расти, но они лежат в тренере, тут я их показывать не буду\n",
    "\n",
    "Так что остаётся лишь взглянуть на SLERP и поедем тюнить модельку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slerp(theta, thetas, lamb):\n",
    "\n",
    "    for i in range(len(thetas) - 1):\n",
    "\n",
    "        delta_1 = thetas[i] - theta\n",
    "        delta_2 = thetas[i + 1] - theta\n",
    "\n",
    "        omega = (\n",
    "            torch.einsum(\n",
    "                \"ij, ij -> i\",\n",
    "                delta_1 / delta_1.norm(p=2, dim=1, keepdim=True),\n",
    "                delta_2 / delta_2.norm(p=2, dim=1, keepdim=True),\n",
    "            )\n",
    "            .unsqueeze(-1)\n",
    "            .arccos()\n",
    "        )\n",
    "\n",
    "        thetas[i + 1] = (\n",
    "            (torch.sin((1 - lamb) * omega) / torch.sin(omega)) * delta_1\n",
    "            + (torch.sin(lamb * omega) / torch.sin(omega)) * delta_2\n",
    "        )\n",
    "\n",
    "    return theta + thetas[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прикольное упражнение на подумать - почему эта имплементация не очень, ответы в скрипте `warp/utils/train.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = torch.rand(3, 2)\n",
    "theta_1 = torch.rand(3, 2)\n",
    "theta_2 = torch.rand(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "slerped = slerp(theta, [theta_1, theta_2], lamb=0.5)\n",
    "assert slerped.shape == theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8703, 0.5297],\n",
       "         [0.1625, 0.7183],\n",
       "         [0.9897, 0.5562]]),\n",
       " tensor([[0.5833, 0.3161],\n",
       "         [0.8885, 0.7056],\n",
       "         [0.5693, 0.4831]]),\n",
       " tensor([[0.4092, 0.5345],\n",
       "         [0.4266, 0.4700],\n",
       "         [0.8235, 0.8636]]),\n",
       " tensor([[9.5895e-01, 2.4779e-01],\n",
       "         [8.0824e-04, 9.6473e-01],\n",
       "         [8.3183e-01, 1.9243e-01]]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slerped, theta, theta_1, theta_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну, об адекватности судить сложно, но по крайней мере оно работает\n",
    "\n",
    "Осталось только собрать датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>A hit at the time but now better categorised a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>I love this movie like no other. Another time ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>This film and it's sequel Barry Mckenzie holds...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>'The Adventures Of Barry McKenzie' started lif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>The story centers around Barry McKenzie who mu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1      \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2      If only to avoid making this type of film in t...      0\n",
       "3      This film was probably inspired by Godard's Ma...      0\n",
       "4      Oh, brother...after hearing about this ridicul...      0\n",
       "...                                                  ...    ...\n",
       "24995  A hit at the time but now better categorised a...      1\n",
       "24996  I love this movie like no other. Another time ...      1\n",
       "24997  This film and it's sequel Barry Mckenzie holds...      1\n",
       "24998  'The Adventures Of Barry McKenzie' started lif...      1\n",
       "24999  The story centers around Barry McKenzie who mu...      1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = load_dataset(\"imdb\", split=[\"train\", \"test\"])\n",
    "train, test = [pd.DataFrame(dataset) for dataset in [train, test]]\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и сказано в задании, возьмём первые 10 токено, только и всего. Важно, что токенизировать их будем через SFT, потому что их же будем пихать в SFT-модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-08-05 17:48:23.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mwarp.utils.data\u001b[0m:\u001b[36mprepare_warp_dataset\u001b[0m:\u001b[36m164\u001b[0m - \u001b[1mStarting tokenizing `text`\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'text'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "what = prepare_warp_dataset(\n",
    "    pl.DataFrame(train).to_dict(as_series=False),\n",
    "    tokenizer=sft_tokenizer,\n",
    "    max_length=10,\n",
    ")\n",
    "what"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([   40, 26399,   314,  3001,   327, 47269, 20958,    12,    56, 23304]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['this movie is a waste of time. I was very disappointed. I was very disappointed. I was']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sft_tokenizer.batch_decode(\n",
    "    sft_model.generate(\n",
    "        temperature=0.9,\n",
    "        **sft_tokenizer([\"this movie is\"], return_tensors=\"pt\"),\n",
    "    ).sequences\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, остаётся собрать трейн луп. Я бы с удовольствием сделал его как-нибудь красиво через lightning, но тут довольно много всего, так что внес в отдельный класс, который можно (и нужно) посмотреть в `warp/structs/warp_trainer.py`. Если я нигде не ошибся в реализации, то и сам алгоритм чисто теоретически должен работать. Запустить весь процесс можно командой ниже. Как обычно, рекомендую предварительно ознакомиться с параметрами в `warp/configs/warp_config.yaml`\n",
    "\n",
    "Основные параметры - как просят в задании. Оставшиеся вопросы - lr оптимайзера, потому что он очень важен, и scheduler. Они говорят, что есть warmup, но на этом всё. Я импортнул подобный из лайтнинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry run python warp/train_warp.py --config-name warp_config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
