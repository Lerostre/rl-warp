{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from scipy.stats import entropy\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm, trange\n",
    "from transformers import (\n",
    "    DistilBertForSequenceClassification,\n",
    "    DistilBertTokenizerFast,\n",
    "    GPT2LMHeadModel,\n",
    "    GPT2TokenizerFast,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from trl import DPOTrainer\n",
    "\n",
    "from scripts.utils.data import df_self_product\n",
    "from scripts.utils.misc import seed_everything\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at lvwerra/distilbert-imdb-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"lvwerra/distilbert-imdb-cased\"\n",
    "\n",
    "reward_tokenizer = DistilBertTokenizerFast.from_pretrained(model_name, max_length=512)\n",
    "reward_model = DistilBertForSequenceClassification.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"lvwerra/gpt2-imdb\"\n",
    "\n",
    "sft_tokenizer = GPT2TokenizerFast.from_pretrained(model_name, max_length=512)\n",
    "sft_model = GPT2LMHeadModel.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>A hit at the time but now better categorised a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>I love this movie like no other. Another time ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>This film and it's sequel Barry Mckenzie holds...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>'The Adventures Of Barry McKenzie' started lif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>The story centers around Barry McKenzie who mu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1      \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2      If only to avoid making this type of film in t...      0\n",
       "3      This film was probably inspired by Godard's Ma...      0\n",
       "4      Oh, brother...after hearing about this ridicul...      0\n",
       "...                                                  ...    ...\n",
       "24995  A hit at the time but now better categorised a...      1\n",
       "24996  I love this movie like no other. Another time ...      1\n",
       "24997  This film and it's sequel Barry Mckenzie holds...      1\n",
       "24998  'The Adventures Of Barry McKenzie' started lif...      1\n",
       "24999  The story centers around Barry McKenzie who mu...      1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = load_dataset(\"imdb\", split=[\"train\", \"test\"])\n",
    "train, test = [pd.DataFrame(dataset) for dataset in [train, test]]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = (\n",
    "    df_self_product(train, partition_col=\"label\")\n",
    "    .sample(10000)\n",
    "    .rename({\"text_0\": \"chosen\", \"text_1\": \"rejected\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dfd05f936a34098a4ed6063ce18c3a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "from typing import Sequence, Literal, Tuple, List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "def multi_join(\n",
    "    df_list: Sequence[pl.DataFrame | pl.LazyFrame],\n",
    "    on: Sequence[str | None] | str | None,\n",
    "    how: pl._typing.JoinStrategy = \"inner\",\n",
    ") -> pl.DataFrame | pl.LazyFrame:\n",
    "    \"\"\"\n",
    "    Join the list of pl.DataFrame of length N\n",
    "    using respective keys of length N-1 as `on`\n",
    "    with a given `how` method, common for all dataframes\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(on, Sequence):\n",
    "        on = [on] * len(df_list)\n",
    "\n",
    "    while len(df_list) > 1:\n",
    "        df_list[0] = df_list[0].join(df_list[1], on=on[0], how=how)\n",
    "        del df_list[1], on[1]\n",
    "        gc.collect()\n",
    "\n",
    "    return df_list[0]\n",
    "\n",
    "\n",
    "def sample_it(\n",
    "    s: pl.Series, n_samples: int | float | None, sample_mode: Literal[\"exact\", \"approximate\"] = \"exact\"\n",
    ") -> pl.Series:\n",
    "    \"\"\"\n",
    "    Custom pl.LazyFrame.sample implementation using shuffle or binomial sampling techinques\n",
    "    \"\"\"\n",
    "    if isinstance(n_samples, float):\n",
    "        n_samples = int(s.len() * n_samples)\n",
    "    elif n_samples is None:\n",
    "        n_samples = s.len()\n",
    "\n",
    "    if sample_mode == \"exact\":\n",
    "        values = np.random.permutation(np.hstack([np.ones(n_samples), np.zeros(s.len() - n_samples)]))\n",
    "    elif sample_mode == \"approximate\":\n",
    "        values = np.random.binomial(1, n_samples / s.len(), s.len())\n",
    "\n",
    "    return pl.Series(\n",
    "        values=values,\n",
    "        dtype=pl.Boolean,\n",
    "    )\n",
    "\n",
    "\n",
    "def df_self_product(\n",
    "    dataset: pd.DataFrame | pl.DataFrame,\n",
    "    partition_col: str,\n",
    "    fields: Sequence[str] | str | None = None,\n",
    "    n_samples: int | float | None = None,\n",
    "    sample_mode: Literal[\"exact\", \"approximate\"] = \"approximate\",\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Dataframe self cross product of different columns with sampling if necessary\n",
    "    \"\"\"\n",
    "\n",
    "    if fields is None:\n",
    "        fields = dataset.columns\n",
    "\n",
    "    dataset = pl.DataFrame(dataset).partition_by(partition_col, as_dict=True, include_key=False)\n",
    "    dataset = [dataset[key].select(pl.all().name.suffix(f\"_{key[0]}\")).lazy() for key in dataset]\n",
    "    dataset = multi_join(dataset, on=fields, how=\"cross\")\n",
    "\n",
    "    # pl.LazyFrame has no efficient method of sampling, thie block below is a placeholder for the future\n",
    "    if n_samples is not None:\n",
    "        dataset = (\n",
    "            dataset.with_columns(\n",
    "                sample=pl.first().map_batches(lambda x: sample_it(x, n_samples=n_samples, sample_mode=sample_mode))\n",
    "            )\n",
    "            .filter(pl.col(\"sample\"))\n",
    "            .drop(\"sample\")\n",
    "        )\n",
    "\n",
    "    return dataset.collect(streaming=True)\n",
    "\n",
    "\n",
    "def prepare_reward_dataset(\n",
    "    examples: tuple[list], tokenizer, verbose: bool = False, max_length: int = 512, truncation: bool = True\n",
    ") -> Dataset:\n",
    "    new_examples = dict(\n",
    "        zip(\n",
    "            [\"input_ids_chosen\", \"attention_mask_chosen\", \"input_ids_rejected\", \"attention_mask_rejected\"],\n",
    "            [[0] * len(examples) for _ in range(4)],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    def tokenize_pair(idx):\n",
    "        tokenized_chosen = tokenizer(examples[\"chosen\"][idx], truncation=truncation, max_length=max_length)\n",
    "        tokenized_rejected = tokenizer(examples[\"rejected\"][idx], truncation=truncation, max_length=max_length)\n",
    "\n",
    "        new_examples[\"input_ids_chosen\"][idx] = tokenized_chosen[\"input_ids\"]\n",
    "        new_examples[\"attention_mask_chosen\"][idx] = tokenized_chosen[\"attention_mask\"]\n",
    "        new_examples[\"input_ids_rejected\"][idx] = tokenized_rejected[\"input_ids\"]\n",
    "        new_examples[\"attention_mask_rejected\"][idx] = tokenized_rejected[\"attention_mask\"]\n",
    "\n",
    "    iter_tuple = range(len(examples[\"chosen\"]))\n",
    "    if verbose:\n",
    "        iter_tuple = tqdm(iter_tuple)\n",
    "\n",
    "    Parallel(n_jobs=-1, prefer=\"threads\")(delayed(tokenize_pair)(idx) for idx in iter_tuple)\n",
    "    return Dataset.from_dict(new_examples)\n",
    "\n",
    "\n",
    "reward_dataset = prepare_reward_dataset(sets, reward_tokenizer, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"../artifacts/reward_dataset.hf\"):\n",
    "    reward_dataset = reward_dataset.train_test_split(test_size=0.2)\n",
    "    reward_dataset.save_to_disk(\"../artifacts/reward_dataset.hf\")\n",
    "else:\n",
    "    reward_dataset = load_from_disk(\"../artifacts/reward_dataset.hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids_chosen', 'attention_mask_chosen', 'input_ids_rejected', 'attention_mask_rejected'],\n",
       "        num_rows: 8000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids_chosen', 'attention_mask_chosen', 'input_ids_rejected', 'attention_mask_rejected'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_dataset = reward_dataset.train_test_split(test_size=0.2)\n",
    "reward_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_prompts(dataset, ):\n",
    "    dataset[\"text\"] = \n",
    "    imdb_prompts = [row[\"text\"].split(\".\")[0] for row in dataset[\"train\"] if row[\"label\"] == 1]\n",
    "    return np.random.choice(imdb_prompts, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 1:23:12, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7, training_loss=0.6862846102033343, metrics={'train_runtime': 5837.0332, 'train_samples_per_second': 1.371, 'train_steps_per_second': 0.001, 'total_flos': 0.0, 'train_loss': 0.6862846102033343, 'epoch': 0.896})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from trl import RewardTrainer, RewardConfig\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import os\n",
    "\n",
    "peft_params = OmegaConf.load('../scripts/configs/peft_reward.yaml')\n",
    "peft_config = LoraConfig(**peft_params)\n",
    "\n",
    "reward_trainer_params = OmegaConf.load('../scripts/configs/config_reward_trainer.yaml')\n",
    "reward_config = RewardConfig(**reward_trainer_params)\n",
    "\n",
    "trainer = RewardTrainer(\n",
    "    model=reward_model,\n",
    "    args=reward_config,\n",
    "    tokenizer=reward_tokenizer,\n",
    "    train_dataset=reward_dataset[\"train\"],\n",
    "    eval_dataset=reward_dataset[\"test\"]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "conf = OmegaConf.load('../scripts/configs/reward_config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'defaults': ['reward_peft', 'reward_trainer']}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OmegaConf.to_container(conf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
